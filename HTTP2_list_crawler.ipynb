{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTP2 List Crawler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script uses a CSV input of URLs to render one and a time and extract HTTP2 status. As it runs, it incrementally outputs the data into an output CSV you define. You only need to define your input and output CSV paths, and your Chromedriver location. You can, optionally, change the user agent, where defined below. All needed documentation is in the comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "This first cell is the the only cell you should need to make changes to.\n",
    "Be sure the read all commented notes in this first cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a fail safe, the script saves X number of rows of urls at a time to the output file, designate the amount of rows here. \n",
    "## You can make this slightly higher for CSVs over 10k URLs, but this script is untested above that many URLs.\n",
    "rows_per_run = 10\n",
    "\n",
    "## If you'd like to loop through a CSV of URLs with URL in the 'url' column, paste that path here.\n",
    "## !IMPORTANT! As part of the fail safe described above, the script removes rows_per_run rows of urls at a time from this source file, so be sure to have a backup of this file before you run this script on it. \n",
    "url_source = '/Users/jsciortino/Desktop/url-input.csv'\n",
    "\n",
    "## Designate the path where you'd like the output of results. The script will create the file for you.\n",
    "url_output = '/Users/jsciortino/Desktop/output.csv'\n",
    "\n",
    "## Designate the local path of your Chromedriver. If you need to install: https://chromedriver.chromium.org/downloads\n",
    "## On Mac, the Chromedriver path may not have a file extension. On Windows it will likely have an .exe file extension.\n",
    "chrome_path = '/Users/jsciortino/py/chromedriver-85'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports the necessary libraries\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pandas as pd\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# HTTP2 Function libs\n",
    "import socket\n",
    "import ssl\n",
    "import csv\n",
    "import argparse\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This creates the blank output file as the url_output path designated above. No changes needed.\n",
    "df_output = pd.DataFrame(columns = ['url', 'http2'])\n",
    "df_output.to_csv(url_output, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Program\n",
    "The program will loop through each URL, extracting Mixed Content errors from the Chrome Console Log (webdriver.Chrome.get_log).<br>\n",
    "It renders in full Chrome, including JavaScript, a rate of about 1-5 seconds per URL depending on host server speed and your internet connection.<br>\n",
    "It has not been tested on a list larger than 10k URLs.\n",
    "##### No changes are needed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Enables browser logging & sets options\n",
    "## No further changes are required\n",
    "\n",
    "d = DesiredCapabilities.CHROME\n",
    "d['loggingPrefs'] = { 'browser':'ALL' }\n",
    "\n",
    "opt = webdriver.ChromeOptions()\n",
    "opt.add_experimental_option('w3c', False)\n",
    "\n",
    "## HTTP2 config, including User Agent if you choose to modify\n",
    "socket.setdefaulttimeout(5)\n",
    "headers = {\"user-agent\" : \"Mozilla/5.0 (Linux; Android 6.0.1; Nexus 5X Build/MMB29P) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/W.X.Y.Zâ€¡ Mobile Safari/537.36 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_source = pd.read_csv(url_source)\n",
    "\n",
    "while len(df_source) > 0:\n",
    "    new_rows = df_source.iloc[ 0: rows_per_run, : ]\n",
    "    print(str(len(new_rows)) + ' rows to process...')\n",
    "    url_list = new_rows['url'].tolist()\n",
    "    \n",
    "    page_output_df = pd.DataFrame()\n",
    "    \n",
    "    d = DesiredCapabilities.CHROME\n",
    "    d['loggingPrefs'] = { 'browser':'ALL' }\n",
    "    opt = webdriver.ChromeOptions()\n",
    "    opt.add_experimental_option('w3c', False)\n",
    "\n",
    "    for url in url_list:\n",
    "        driver = webdriver.Chrome(chrome_path, options=opt,desired_capabilities=d)\n",
    "        \n",
    "        try:\n",
    "            driver.get(url)\n",
    "                \n",
    "            try:\n",
    "                HOST = urlparse(url).netloc\n",
    "                PORT = 443\n",
    "\n",
    "                ctx = ssl.create_default_context()\n",
    "                ctx.set_alpn_protocols(['h2', 'spdy/3', 'http/1.1'])\n",
    "\n",
    "                conn = ctx.wrap_socket(\n",
    "                    socket.socket(socket.AF_INET, socket.SOCK_STREAM), server_hostname=HOST)\n",
    "                conn.connect((HOST, PORT))\n",
    "\n",
    "                pp = conn.selected_alpn_protocol()\n",
    "\n",
    "                if pp == \"h2\":\n",
    "                    http2 = True\n",
    "                else:\n",
    "                    http2 = False\n",
    "\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "            \n",
    "            page_results = {'http2':http2, 'loaded':True}\n",
    "            page_row_df = pd.DataFrame(data=page_results, index=[0])\n",
    "            page_row_df['url'] = url\n",
    "            page_output_df = page_output_df.append(page_row_df, ignore_index=True, sort=False)\n",
    "\n",
    "            # Quit browser each time to avoid zombies\n",
    "            driver.quit()\n",
    "    \n",
    "        ## A failsafe to prevent URLs that won't load from blocking script from continuing\n",
    "        except:\n",
    "            page_results = {'http2':http2, 'loaded':False}\n",
    "            page_row_df['url'] = url\n",
    "            page_output_df = page_output_df.append(page_row_df, ignore_index=True, sort=False)\n",
    "            driver.quit()\n",
    "            print(\"Skipping 1 URL that failed to render.\")\n",
    "\n",
    "        \n",
    "    # Read the output CSV, write the new rows, then write the output back again\n",
    "    df_output = pd.read_csv(url_output)\n",
    "    df_output = df_output.append(page_output_df, ignore_index=True, sort=False)\n",
    "    df_output.to_csv(url_output, index=False)\n",
    "    \n",
    "    # If all the URLs were processed, write the source list back without the processed URLs\n",
    "    updated_df = df_source.iloc[ rows_per_run+1: , : ]\n",
    "    updated_df.to_csv(url_source, index=False)\n",
    "    df_source = pd.read_csv(url_source)\n",
    "    \n",
    "driver.quit()\n",
    "\n",
    "print(\"Finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
